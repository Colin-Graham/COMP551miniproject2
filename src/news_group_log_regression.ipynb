{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model as m\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we intend to test each solver independently and then compare them afterwards\n",
    "clf_newton = m.Classifier(1,LogisticRegression(solver ='newton-cg'))\n",
    "clf_saga = m.Classifier(1,LogisticRegression(solver ='saga'))\n",
    "clf_lib = m.Classifier(1,LogisticRegression(solver ='liblinear'))\n",
    "clf_sag = m.Classifier(1,LogisticRegression(solver ='sag'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop word sets specified for this data set\n",
    "path = \"../data/stop_words_news_groups/\"\n",
    "with open(path+\"stop_words_no_numbers.txt\", 'r') as content_file:\n",
    "        content = content_file.read().replace(\" \",\"\").replace(\"\\n\",\"\").split(\",\")\n",
    "        stop_words_no_nums = frozenset(content)\n",
    "with open(path+\"stop_words_with_nums.txt\", 'r') as content_file:\n",
    "        content = content_file.read().replace(\" \",\"\").replace(\"\\n\",\"\").split(\",\")\n",
    "        stop_words_with_nums = frozenset(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_trial_1 = { \n",
    "            #penalty is l2 by default\n",
    "            'vect__max_features': (1000, 10000), # we dont want features to exceed observations (because of overfitting)\n",
    "            'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "            'tfidf__norm': ('l1','l2',None),\n",
    "            'vect__stop_words' : [stop_words_no_nums, stop_words_with_nums],\n",
    "            'clf__max_iter': ([50,150]), #two extremes\n",
    "            'clf__C':(10,1.0),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    6.8s\n"
     ]
    }
   ],
   "source": [
    "#### TEST 1 looking at saga ####\n",
    "clf_saga.fit(params_trial_1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_saga.eval_on_test([],False)\n",
    "clf_saga.learning_curve([0.2,0.4,0.6,0.8,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "        from sklearn.feature_extraction.text import TfidfTransformer\n",
    "        from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score,plot_confusion_matrix\n",
    "        from sklearn.model_selection import GridSearchCV,learning_curve\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        from pprint import pprint\n",
    "        from time import time\n",
    "        import matplotlib.pyplot as plt\n",
    "        from sklearn.pipeline import Pipeline\n",
    "        \n",
    "        print(\"scores!\")\n",
    "        means = clf_saga.clf.cv_results_['mean_test_score']\n",
    "        stds = clf_saga.clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf_saga.clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for\"\n",
    "                % (mean, std * 2))\n",
    "            \n",
    "        print(\"Best score:\")\n",
    "        print(\"%0.3f (+/-%0.03f)\" % (clf_saga.clf.best_score_, std * 2))\n",
    "        print(\"with parameters set:\")\n",
    "        best_parameters = clf_saga.clf.best_estimator_.get_params()\n",
    "        for param_name in sorted(params_trial_1.keys()):\n",
    "            print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
