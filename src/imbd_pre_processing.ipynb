{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"../data/imbd/train.txt\",header=None)\n",
    "test = pd.read_csv(\"../data/imbd/test.txt\",header=None)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score,confusion_matrix\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Load some categories from the training set\n",
    "#categories = [\n",
    "    #'alt.atheism',\n",
    "    #'talk.religion.misc',\n",
    "#]\n",
    "# Uncomment the following to do the analysis on all the categories\n",
    "#categories = None\n",
    "\n",
    "#print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "#print(categories)\n",
    "\n",
    "#print(\"%d documents\" % len(data.filenames))\n",
    "#print(\"%d categories\" % len(data.target_names))\n",
    "#print()\n",
    "\n",
    "# #############################################################################\n",
    "# Define a pipeline combining a text feature extractor with a simple\n",
    "# classifier\n",
    "pipeline = Pipeline(steps = [\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LogisticRegression()),\n",
    "])\n",
    "\n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "parameters = {\n",
    "    'vect__min_df': ([0]),\n",
    "    #'vect__max_features': (None, 5000, 10000, 100000),\n",
    "    #'vect__ngram_range': ((1, 1)),  # unigrams or bigrams\n",
    "    'tfidf__use_idf': ([False]),\n",
    "    # 'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__C': ([0.01,0.1]),\n",
    "    #'clf__penalty': ('l2', 'l1'),\n",
    "    # 'clf__max_iter': (1,2),\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(pipeline, parameters,cv=2, n_jobs=-1, verbose=5, refit = True,return_train_score = True)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameter set:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(train[0], train[1])\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "    \n",
    "    print(\"scores!\")\n",
    "    means = grid_search.cv_results_['mean_test_score']\n",
    "    stds = grid_search.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, grid_search.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "        \n",
    "    print(\"Best score:\")\n",
    "    print(\"%0.3f (+/-%0.03f)\" % (grid_search.best_score_, std * 2))\n",
    "    print(\"with parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    print(grid_search)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import itertools\n",
    "#from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "test = fetch_20newsgroups(subset='test')\n",
    "y_test = test.target\n",
    "y_pred = grid_search.predict(test.data)\n",
    "#np.mean(x==tets.target)\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred)\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,y_pred,average='micro')))\n",
    "print('Recall Score : ' + str(recall_score(y_test,y_pred,average='micro')))\n",
    "print('F1 Score : ' + str(f1_score(y_test,y_pred,average='micro')))\n",
    "print('Confusion Matrix : \\n' + str(cnf_matrix))\n",
    "class_names = test.target_names\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(self,stop_words,min_df,max_features,ngram_upper_bound):\n",
    "        train_size = len(self.train[\"text\"])\n",
    "        test_size = len(self.test[\"text\"])\n",
    "        vertical_stack = pd.concat([self.train, self.test], axis=0)\n",
    "        tfidf_transformer = TfidfTransformer()\n",
    "        if max_features > 0:\n",
    "            vectorizer = CountVectorizer(ngram_range=(1, ngram_upper_bound),min_df = min_df, max_features= max_features,stop_words=stop_words)\n",
    "        else:\n",
    "            vectorizer = CountVectorizer(ngram_range=(1, ngram_upper_bound),min_df = min_df,stop_words=stop_words)\n",
    "        \n",
    "        formated_data = vectorizer.fit_transform(vertical_stack[\"text\"])\n",
    "        formated_data = tfidf_transformer.fit_transform(formated_data).toarray()\n",
    "        self.X_train = formated_data[0:train_size][:]\n",
    "        self.X_test = formated_data[train_size:][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'tfidf__use_idf': [False], 'vect__min_df': [0]}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    9.9s remaining:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   11.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 16.235s\n",
      "\n",
      "scores!\n",
      "0.900 (+/-0.004) for {'tfidf__use_idf': False, 'vect__min_df': 0}\n",
      "Best score:\n",
      "0.900 (+/-0.004)\n",
      "with parameters set:\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__min_df: 0\n",
      "\n",
      "Evaluation on test set:\n",
      "\n",
      "Accuracy Score : 0.8251460435475305\n",
      "Precision Score : 0.8251460435475305\n",
      "Recall Score : 0.8251460435475305\n",
      "F1 Score : 0.8251460435475305\n",
      "Confusion Matrix : \n",
      "[[239   2   0   0   2   1   0   0   0   0   0   2   1   8   5  24   3   7\n",
      "    1  24]\n",
      " [  3 299  16   7   6  19   3   3   0   6   1   5  10   0   3   2   1   2\n",
      "    1   2]\n",
      " [  2  18 275  38  13  15   4   2   0   6   0   1   4   0   4   1   0   0\n",
      "    7   4]\n",
      " [  1  10  23 276  26   4  15   4   1   0   0   3  26   1   1   0   1   0\n",
      "    0   0]\n",
      " [  0   6   5  17 321   0   8   2   1   3   1   0  13   2   0   0   3   0\n",
      "    2   1]\n",
      " [  1  39  37   5   4 285   4   0   1   0   1   2   8   1   3   1   1   1\n",
      "    0   1]\n",
      " [  1   2   1   9   8   0 346   7   1   1   1   1   6   3   2   0   0   0\n",
      "    0   1]\n",
      " [  0   3   1   1   2   0  12 349   9   3   0   0  10   0   1   0   3   0\n",
      "    2   0]\n",
      " [  0   0   0   1   0   0   4  10 374   2   0   0   2   1   0   1   1   0\n",
      "    1   1]\n",
      " [  0   1   1   0   3   0   5   1   0 366  16   0   1   0   0   0   0   0\n",
      "    2   1]\n",
      " [  0   0   0   1   2   0   1   0   0   5 387   0   0   0   0   0   2   0\n",
      "    1   0]\n",
      " [  0   2   2   1   2   2   4   2   1   4   0 369   2   2   0   0   3   0\n",
      "    0   0]\n",
      " [  0   7   8  23   8   2   9   5   4   3   0   9 297   8   2   3   3   0\n",
      "    1   1]\n",
      " [  6   7   4   3   2   3   4   9   0   2   2   1   8 322   3   5   1   5\n",
      "    5   4]\n",
      " [  1   7   0   0   4   0   2   0   0   0   1   0   2   6 364   3   1   0\n",
      "    2   1]\n",
      " [  5   0   2   0   0   0   0   0   0   0   0   0   2   1   2 379   0   0\n",
      "    0   7]\n",
      " [  1   0   0   1   1   0   2   1   1   3   0   3   0   3   1   1 328   1\n",
      "   12   5]\n",
      " [ 16   1   0   0   0   3   0   2   0   1   0   3   1   0   1   7   3 329\n",
      "    9   0]\n",
      " [  1   2   0   0   2   1   0   0   1   2   1   2   0   2   5   4  95   4\n",
      "  180   8]\n",
      " [ 43   3   1   1   0   0   0   0   0   1   0   0   1   5   4  37  13   3\n",
      "    9 130]]\n"
     ]
    }
   ],
   "source": [
    "import model\n",
    "from sklearn.svm import LinearSVC\n",
    "c = model.Classifier(1,LinearSVC())\n",
    "c.baseline_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "ccc = model.Classifier(1,DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'tfidf__use_idf': [False], 'vect__min_df': [0]}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   12.4s remaining:   18.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   12.6s finished\n",
      "/Users/kaan/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 19.680s\n",
      "\n",
      "scores!\n",
      "0.657 (+/-0.032) for {'tfidf__use_idf': False, 'vect__min_df': 0}\n",
      "Best score:\n",
      "0.657 (+/-0.032)\n",
      "with parameters set:\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__min_df: 0\n",
      "\n",
      "Evaluation on test set:\n",
      "\n",
      "Accuracy Score : 0.5594795539033457\n",
      "Precision Score : 0.5594795539033457\n",
      "Recall Score : 0.5594795539033457\n",
      "F1 Score : 0.5594795539033457\n",
      "Confusion Matrix : \n",
      "[[194   7   3   4  10   2   1   3   1   4   5   3   1   5   5  47   7   4\n",
      "    2  11]\n",
      " [  4 201  33  18  27  39  12   5   5   6   2   2  15   2   9   3   0   3\n",
      "    3   0]\n",
      " [  6  59 198  45  17  20   8   5   4   5   0   5   7   1   8   1   2   1\n",
      "    2   0]\n",
      " [  3  48  64 172  32  15  10   6   3   0   2   2  19   4   4   3   2   0\n",
      "    3   0]\n",
      " [  5  38  31  49 182  11  23   8   3   6   4   4  12   2   1   3   1   0\n",
      "    2   0]\n",
      " [  5  69  59  21  16 184   3   4   7   4   2   2   8   4   4   0   1   0\n",
      "    1   1]\n",
      " [  4  18  14  18  17   7 287   9   1   1   2   1   4   3   2   0   2   0\n",
      "    0   0]\n",
      " [ 10  18  20  16  15   9  31 209  23   7   2   1  11   9   5   4   5   1\n",
      "    0   0]\n",
      " [  7  15  10   8   4   1  13  31 287   1   4   1   7   3   2   1   2   0\n",
      "    0   1]\n",
      " [  4  12   4   7  10   9   7  13   3 270  31   0   6  12   1   4   3   1\n",
      "    0   0]\n",
      " [  2   5   3   4   6   4   6   4   4  34 316   0   2   2   4   1   1   0\n",
      "    1   0]\n",
      " [  3  18  10   4  10   9   7   2   4   6   2 297   3   5   4   3   5   0\n",
      "    4   0]\n",
      " [ 12  45  31  36  33  14  14  21  17  18  10  13 102   8   9   4   3   1\n",
      "    1   1]\n",
      " [ 17  41  17  14  10  12  26  23   5  13  11   4  18 147  10   8   4   7\n",
      "    6   3]\n",
      " [  9  11   8   8  10   5   8  13   4  13   4   9  11  16 250   6   6   0\n",
      "    2   1]\n",
      " [ 30  11   8   2   5   3   3   7   1   6   1   1   2   9   3 292   4   2\n",
      "    2   6]\n",
      " [  9  13   6   4   5   3   8  17   8  15   4  24   2   4   6   9 210   3\n",
      "    9   5]\n",
      " [ 19   4   3   4   7   3   3   6   3   5   7   6   3   6   7  14  17 253\n",
      "    1   5]\n",
      " [ 11  11   5   4   6   6   2  14   5   7   6   8   4  18   4   9  71   6\n",
      "  107   6]\n",
      " [ 49   4   2   3   4   6   0   6   6   5   5   4   5   6   6  61  15   1\n",
      "    7  56]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "c3 = model.Classifier(1,RandomForestClassifier())\n",
    "c3.baseline_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'tfidf__use_idf': [False], 'vect__min_df': [0]}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   39.4s remaining:   59.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   39.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 66.577s\n",
      "\n",
      "scores!\n",
      "0.353 (+/-0.009) for {'tfidf__use_idf': False, 'vect__min_df': 0}\n",
      "Best score:\n",
      "0.353 (+/-0.009)\n",
      "with parameters set:\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__min_df: 0\n",
      "\n",
      "Evaluation on test set:\n",
      "\n",
      "Accuracy Score : 0.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mix of label input types (string and number)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-e7a4d95ed460>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mc4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mc4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbaseline_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/school/comp551/A2/COMP551miniproject2/src/model.py\u001b[0m in \u001b[0;36mbaseline_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m# default C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_on_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/school/comp551/A2/COMP551miniproject2/src/model.py\u001b[0m in \u001b[0;36meval_on_test\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;31m#cnf_matrix = confusion_matrix(y_test,y_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy Score : '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Precision Score : '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Recall Score : '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'F1 Score : '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1567\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1569\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1570\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1413\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1415\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;31m# Check that we don't mix string type with number type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mix of label input types (string and number)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Mix of label input types (string and number)"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "c4 = model.Classifier(0,AdaBoostClassifier())\n",
    "c4.baseline_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'tfidf__use_idf': [False], 'vect__min_df': [0]}\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   25.3s remaining:   37.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   25.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 48.606s\n",
      "\n",
      "scores!\n",
      "0.640 (+/-0.012) for {'tfidf__use_idf': False, 'vect__min_df': 0}\n",
      "Best score:\n",
      "0.640 (+/-0.012)\n",
      "with parameters set:\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__min_df: 0\n",
      "\n",
      "Evaluation on test set:\n",
      "\n",
      "Accuracy Score : 0.5528412108337759\n",
      "Precision Score : 0.5528412108337759\n",
      "Recall Score : 0.5528412108337759\n",
      "F1 Score : 0.5528412108337759\n",
      "Confusion Matrix : \n",
      "[[136   5   3   2   4   3   3   7   6   8   4   1   7  14   6  25  12   5\n",
      "   12  56]\n",
      " [  4 178  16  23  23  37  20   4   4   7   3   7  20  10  15   8   5   4\n",
      "    0   1]\n",
      " [  1  28 235  34  14  27   5   4   3   7   2   4  11   1   4   1   4   3\n",
      "    4   2]\n",
      " [  2  25  29 158  25  15  13  13   4   7   3   5  51  16   6   5   3   3\n",
      "    5   4]\n",
      " [  1  24  10  23 212   6  22  13   5   3   1   2  29  12  10   4   4   0\n",
      "    4   0]\n",
      " [  1  33  54  18  16 192   3  12   5   7   2   9  11  11   6   1   4   1\n",
      "    6   3]\n",
      " [  3   4   6  24  17   2 268  10   6   5   6   4  11   7   4   3   7   2\n",
      "    1   0]\n",
      " [  3   6   4   8   1  10  20 214  25   4   3   6  38  12   8   6  17   2\n",
      "    6   3]\n",
      " [  5   6   2   1   4   6   9   8 315   9   2   4   6   4   1   2   6   1\n",
      "    3   4]\n",
      " [  8   8   6   8   4   0   5  11   5 226  46   1   8  23   7   4   5   3\n",
      "    6  13]\n",
      " [  2   6   2   3   6   0   4   1   3  57 281   1   7   5   4   6   3   1\n",
      "    4   3]\n",
      " [  5   8  12  10   7   6   2   1   4   4   1 271  15   8   5   3  15   1\n",
      "   12   6]\n",
      " [  7  36  24  29  22  18  14  21  16   7   7   8 117  14  19   5  12   1\n",
      "    7   9]\n",
      " [ 13  24  14   8  14   9   4  16   3  13   4   4  26 177   6  14   9   9\n",
      "   14  15]\n",
      " [  5  15   7   2  11   5   6  10   7   7   6   5  17  13 241   5  10   2\n",
      "   11   9]\n",
      " [ 11   7   2   2   0   5   2   2   4   9   3   0  13  11   6 277   6   4\n",
      "    6  28]\n",
      " [  9   1   1   2   1   3   7   5   6   3   3   8   8  16   9   9 235   1\n",
      "   26  11]\n",
      " [ 25   4   2   1   5   1   2   1   2  13   4   1   7  12  11   8  14 227\n",
      "   22  14]\n",
      " [  5   7   5   4   2   2   1  11   2   7   4   6   7  15   6  10  84   1\n",
      "  121  10]\n",
      " [ 37   6   5   1   2   3   2   6   2   4   4   3   4  13   8  27  22   6\n",
      "   13  83]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "ccc = model.Classifier(1,DecisionTreeClassifier())\n",
    "ccc.baseline_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
